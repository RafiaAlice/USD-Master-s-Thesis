{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrogram_vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pickle\n",
    "from keras import layers, metrics, applications\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from keras import layers\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "# from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training (4138, 256, 94) (4138,)\n",
      "Validation (1380, 256, 94) (1380,)\n",
      "Test (1380, 256, 94) (1380,)\n"
     ]
    }
   ],
   "source": [
    "infile = open('./csDataframe.pkl', 'rb')\n",
    "data = pickle.load(infile)\n",
    "infile.close()\n",
    "set = []\n",
    "for row in data.itertuples():\n",
    "    #x=loaded[row.File_Name]['x'][int(row.Start*loaded[row.File_Name]['sr']):int(row.End*loaded[row.File_Name]['sr'])]\n",
    "    x, sr = row.npArr , 4000\n",
    "    \n",
    "    X = np.abs(librosa.stft(x,n_fft = 511, hop_length = 128))\n",
    "    Xdb = librosa.amplitude_to_db(abs(X))\n",
    "\n",
    "    np.reshape(Xdb,(1,256,94,1))\n",
    "\n",
    "    \n",
    "    if(row[5] == 0 and row[6] == 0): set.append((Xdb,0))\n",
    "    else: set.append((Xdb,1))\n",
    "\n",
    "x,y = zip(*set)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "combine_X, test_X, combine_y, test_y = train_test_split(\n",
    "    x,\n",
    "    y,\n",
    "    test_size = 0.2, \n",
    "    random_state = 2018)\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(\n",
    "    combine_X,\n",
    "    combine_y,\n",
    "    test_size = 0.25, \n",
    "    random_state = 2018)\n",
    "print('Training', np.shape(train_X), np.shape(train_y))\n",
    "print('Validation', np.shape(valid_X), np.shape(valid_y))\n",
    "print('Test', np.shape(test_X), np.shape(test_y))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=np.array(train_X)\n",
    "train_y = np.array(train_y)\n",
    "valid_X= np.array(valid_X)\n",
    "valid_y= np.array(valid_y)\n",
    "test_X=np.array(test_X)\n",
    "test_y = np.array(test_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.shape(train_X[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/Rafia.Alice/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#train_X = np.expand_dims(train_X, axis=3)\n",
    "#train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 250, 88, 32)       1600      \n",
      "                                                                 \n",
      " spatial_dropout2d (SpatialD  (None, 250, 88, 32)      0         \n",
      " ropout2D)                                                       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 250, 88, 64)       51264     \n",
      "                                                                 \n",
      " spatial_dropout2d_1 (Spatia  (None, 250, 88, 64)      0         \n",
      " lDropout2D)                                                     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 62, 44, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " activation (Activation)     (None, 62, 44, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 62, 44, 256)       147712    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 62, 44, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 31, 22, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 31, 22, 256)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 31, 22, 256)       590080    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 31, 22, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 15, 11, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 15, 11, 256)       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 15, 11, 256)       590080    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 15, 11, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 7, 5, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 7, 5, 256)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 7, 5, 256)         590080    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 7, 5, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 3, 2, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 3, 2, 256)         0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 3, 2, 256)         590080    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 3, 2, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 1, 1, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 1, 1, 256)         0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 1, 1, 512)         1180160   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               131328    \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,872,641\n",
      "Trainable params: 3,872,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rafia.Alice\\Anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "# this is what the results are scored on, so we should keep this\n",
    "def top_3_accuracy(x, y): \n",
    "    return metrics.sparse_top_k_categorical_accuracy(x,y,3)\n",
    "def create_model():\n",
    "    '''\n",
    "    model = Sequential()\n",
    "    model.add(applications.mobilenet.MobileNet(input_shape= (256,94,1),\n",
    "                                    classes=1,\n",
    "                                    weights=None))\n",
    "  \n",
    "    \n",
    "    model.add(Dense(256))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(.5))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    '''\n",
    "\n",
    "    model = Sequential()\n",
    "    input_shape=( 256, 94, 1)\n",
    "\n",
    "    model.add(Conv2D(32, (7, 7), strides=(1, 1), input_shape=input_shape))\n",
    "    model.add(SpatialDropout2D(.2, data_format='channels_last'))\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Dropout(rate=0.2))\n",
    "    #model.add(MaxPooling2D((2, 2), strides=(1, 1)))\n",
    "    #model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(64, (5, 5), strides=(1, 1), padding=\"same\"))\n",
    "    model.add(SpatialDropout2D(.2, data_format='channels_last'))\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Dropout(rate=0.2))\n",
    "    model.add(MaxPooling2D((4, 2), strides=(4, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dropout(rate=0.2))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dropout(rate=0.2))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dropout(rate=0.2))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dropout(rate=0.2))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dropout(rate=0.2))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding=\"same\"))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dropout(rate=0.2))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    #model.add(GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(Dense(256))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(rate=0.2))\n",
    "\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "'''\n",
    "model.add(Dense(64, input_dim=14, init='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# we can think of this chunk as the hidden layer    \n",
    "model.add(Dense(64, init='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# we can think of this chunk as the output layer\n",
    "model.add(Dense(2, init='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# setting up the optimization of our weights \n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd)\n",
    "'''\n",
    "model = create_model()\n",
    "\n",
    "\n",
    "opt = tf.optimizers.Adam(lr=1e-3)\n",
    "model.compile(optimizer=opt, \n",
    "    loss=losses.binary_crossentropy, \n",
    "    metrics=['accuracy', 'Precision', 'AUC', tf.keras.metrics.Recall(), tf.keras.metrics.TrueNegatives()])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "# weight_path=\"{}_weights.best.hdf5\".format('spectro_sound_model')\n",
    "checkpoint = ModelCheckpoint(filepath =\"./check.hDf5\", monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "# reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', \n",
    "#                                    factor=0.8, patience=5, \n",
    "#                                    verbose=1, mode='auto', \n",
    "#                                    epsilon=0.0001, cooldown=5, \n",
    "#                                    min_lr=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=15) # probably needs to be more patient, but kaggle time is limited\n",
    "callbacks_list = [checkpoint, early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tf.keras.backend as K\n",
    "# K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.8583 - accuracy: 0.5401 - precision: 0.5115 - auc: 0.5429 - recall: 0.4369 - true_negatives: 1387.0000\n",
      "Epoch 1: val_loss improved from inf to 0.68500, saving model to .\\check.hDf5\n",
      "65/65 [==============================] - 401s 6s/step - loss: 0.8583 - accuracy: 0.5401 - precision: 0.5115 - auc: 0.5429 - recall: 0.4369 - true_negatives: 1387.0000 - val_loss: 0.6850 - val_accuracy: 0.5833 - val_precision: 0.6283 - val_auc: 0.6461 - val_recall: 0.3218 - val_true_negatives: 592.0000\n",
      "Epoch 2/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.6846 - accuracy: 0.5776 - precision: 0.5613 - auc: 0.5892 - recall: 0.4549 - true_negatives: 1507.0000\n",
      "Epoch 2: val_loss did not improve from 0.68500\n",
      "65/65 [==============================] - 344s 5s/step - loss: 0.6846 - accuracy: 0.5776 - precision: 0.5613 - auc: 0.5892 - recall: 0.4549 - true_negatives: 1507.0000 - val_loss: 0.6894 - val_accuracy: 0.5203 - val_precision: 0.0000e+00 - val_auc: 0.6279 - val_recall: 0.0000e+00 - val_true_negatives: 718.0000\n",
      "Epoch 3/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.6679 - accuracy: 0.6017 - precision: 0.5951 - auc: 0.6371 - recall: 0.4724 - true_negatives: 1573.0000\n",
      "Epoch 3: val_loss improved from 0.68500 to 0.67302, saving model to .\\check.hDf5\n",
      "65/65 [==============================] - 343s 5s/step - loss: 0.6679 - accuracy: 0.6017 - precision: 0.5951 - auc: 0.6371 - recall: 0.4724 - true_negatives: 1573.0000 - val_loss: 0.6730 - val_accuracy: 0.6355 - val_precision: 0.6532 - val_auc: 0.6775 - val_recall: 0.5121 - val_true_negatives: 538.0000\n",
      "Epoch 4/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.6512 - accuracy: 0.6310 - precision: 0.6105 - auc: 0.6660 - recall: 0.5894 - true_negatives: 1467.0000\n",
      "Epoch 4: val_loss improved from 0.67302 to 0.64965, saving model to .\\check.hDf5\n",
      "65/65 [==============================] - 344s 5s/step - loss: 0.6512 - accuracy: 0.6310 - precision: 0.6105 - auc: 0.6660 - recall: 0.5894 - true_negatives: 1467.0000 - val_loss: 0.6496 - val_accuracy: 0.6457 - val_precision: 0.6454 - val_auc: 0.6969 - val_recall: 0.5801 - val_true_negatives: 507.0000\n",
      "Epoch 5/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.6406 - accuracy: 0.6380 - precision: 0.6348 - auc: 0.6861 - recall: 0.5374 - true_negatives: 1597.0000\n",
      "Epoch 5: val_loss improved from 0.64965 to 0.64477, saving model to .\\check.hDf5\n",
      "65/65 [==============================] - 389s 6s/step - loss: 0.6406 - accuracy: 0.6380 - precision: 0.6348 - auc: 0.6861 - recall: 0.5374 - true_negatives: 1597.0000 - val_loss: 0.6448 - val_accuracy: 0.6391 - val_precision: 0.6541 - val_auc: 0.6959 - val_recall: 0.5257 - val_true_negatives: 534.0000\n",
      "Epoch 6/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.6456 - accuracy: 0.6363 - precision: 0.6254 - auc: 0.6779 - recall: 0.5600 - true_negatives: 1546.0000\n",
      "Epoch 6: val_loss did not improve from 0.64477\n",
      "65/65 [==============================] - 426s 7s/step - loss: 0.6456 - accuracy: 0.6363 - precision: 0.6254 - auc: 0.6779 - recall: 0.5600 - true_negatives: 1546.0000 - val_loss: 0.6653 - val_accuracy: 0.5978 - val_precision: 0.7772 - val_auc: 0.6932 - val_recall: 0.2266 - val_true_negatives: 675.0000\n",
      "Epoch 7/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.6259 - accuracy: 0.6390 - precision: 0.6278 - auc: 0.6987 - recall: 0.5657 - true_negatives: 1546.0000\n",
      "Epoch 7: val_loss improved from 0.64477 to 0.63931, saving model to .\\check.hDf5\n",
      "65/65 [==============================] - 361s 6s/step - loss: 0.6259 - accuracy: 0.6390 - precision: 0.6278 - auc: 0.6987 - recall: 0.5657 - true_negatives: 1546.0000 - val_loss: 0.6393 - val_accuracy: 0.6406 - val_precision: 0.6820 - val_auc: 0.7029 - val_recall: 0.4698 - val_true_negatives: 573.0000\n",
      "Epoch 8/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.6273 - accuracy: 0.6484 - precision: 0.6515 - auc: 0.7004 - recall: 0.5384 - true_negatives: 1638.0000\n",
      "Epoch 8: val_loss did not improve from 0.63931\n",
      "65/65 [==============================] - 349s 5s/step - loss: 0.6273 - accuracy: 0.6484 - precision: 0.6515 - auc: 0.7004 - recall: 0.5384 - true_negatives: 1638.0000 - val_loss: 0.6415 - val_accuracy: 0.6275 - val_precision: 0.6504 - val_auc: 0.6906 - val_recall: 0.4834 - val_true_negatives: 546.0000\n",
      "Epoch 9/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.6225 - accuracy: 0.6530 - precision: 0.6486 - auc: 0.7045 - recall: 0.5677 - true_negatives: 1600.0000\n",
      "Epoch 9: val_loss improved from 0.63931 to 0.63262, saving model to .\\check.hDf5\n",
      "65/65 [==============================] - 360s 6s/step - loss: 0.6225 - accuracy: 0.6530 - precision: 0.6486 - auc: 0.7045 - recall: 0.5677 - true_negatives: 1600.0000 - val_loss: 0.6326 - val_accuracy: 0.6449 - val_precision: 0.6604 - val_auc: 0.7097 - val_recall: 0.5347 - val_true_negatives: 536.0000\n",
      "Epoch 10/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.6312 - accuracy: 0.6481 - precision: 0.6407 - auc: 0.6985 - recall: 0.5688 - true_negatives: 1578.0000\n",
      "Epoch 10: val_loss did not improve from 0.63262\n",
      "65/65 [==============================] - 348s 5s/step - loss: 0.6312 - accuracy: 0.6481 - precision: 0.6407 - auc: 0.6985 - recall: 0.5688 - true_negatives: 1578.0000 - val_loss: 0.6410 - val_accuracy: 0.6232 - val_precision: 0.6929 - val_auc: 0.6992 - val_recall: 0.3852 - val_true_negatives: 605.0000\n",
      "Epoch 11/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.6277 - accuracy: 0.6491 - precision: 0.6607 - auc: 0.6952 - recall: 0.5178 - true_negatives: 1681.0000\n",
      "Epoch 11: val_loss improved from 0.63262 to 0.62580, saving model to .\\check.hDf5\n",
      "65/65 [==============================] - 354s 5s/step - loss: 0.6277 - accuracy: 0.6491 - precision: 0.6607 - auc: 0.6952 - recall: 0.5178 - true_negatives: 1681.0000 - val_loss: 0.6258 - val_accuracy: 0.6609 - val_precision: 0.6865 - val_auc: 0.7193 - val_recall: 0.5393 - val_true_negatives: 555.0000\n",
      "Epoch 12/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.6138 - accuracy: 0.6595 - precision: 0.6563 - auc: 0.7156 - recall: 0.5755 - true_negatives: 1612.0000\n",
      "Epoch 12: val_loss did not improve from 0.62580\n",
      "65/65 [==============================] - 351s 5s/step - loss: 0.6138 - accuracy: 0.6595 - precision: 0.6563 - auc: 0.7156 - recall: 0.5755 - true_negatives: 1612.0000 - val_loss: 0.6481 - val_accuracy: 0.6210 - val_precision: 0.7125 - val_auc: 0.7053 - val_recall: 0.3520 - val_true_negatives: 624.0000\n",
      "Epoch 13/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.6047 - accuracy: 0.6663 - precision: 0.6593 - auc: 0.7255 - recall: 0.5971 - true_negatives: 1598.0000\n",
      "Epoch 13: val_loss improved from 0.62580 to 0.61630, saving model to .\\check.hDf5\n",
      "65/65 [==============================] - 348s 5s/step - loss: 0.6047 - accuracy: 0.6663 - precision: 0.6593 - auc: 0.7255 - recall: 0.5971 - true_negatives: 1598.0000 - val_loss: 0.6163 - val_accuracy: 0.6638 - val_precision: 0.6827 - val_auc: 0.7370 - val_recall: 0.5589 - val_true_negatives: 546.0000\n",
      "Epoch 14/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.5875 - accuracy: 0.6822 - precision: 0.6754 - auc: 0.7505 - recall: 0.6208 - true_negatives: 1618.0000\n",
      "Epoch 14: val_loss did not improve from 0.61630\n",
      "65/65 [==============================] - 350s 5s/step - loss: 0.5875 - accuracy: 0.6822 - precision: 0.6754 - auc: 0.7505 - recall: 0.6208 - true_negatives: 1618.0000 - val_loss: 0.6379 - val_accuracy: 0.6420 - val_precision: 0.7165 - val_auc: 0.7020 - val_recall: 0.4199 - val_true_negatives: 608.0000\n",
      "Epoch 15/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.6009 - accuracy: 0.6783 - precision: 0.6751 - auc: 0.7396 - recall: 0.6059 - true_negatives: 1631.0000\n",
      "Epoch 15: val_loss did not improve from 0.61630\n",
      "65/65 [==============================] - 355s 5s/step - loss: 0.6009 - accuracy: 0.6783 - precision: 0.6751 - auc: 0.7396 - recall: 0.6059 - true_negatives: 1631.0000 - val_loss: 0.6245 - val_accuracy: 0.6594 - val_precision: 0.6752 - val_auc: 0.7201 - val_recall: 0.5589 - val_true_negatives: 540.0000\n",
      "Epoch 16/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.5850 - accuracy: 0.6822 - precision: 0.6805 - auc: 0.7461 - recall: 0.6079 - true_negatives: 1643.0000\n",
      "Epoch 16: val_loss improved from 0.61630 to 0.60095, saving model to .\\check.hDf5\n",
      "65/65 [==============================] - 349s 5s/step - loss: 0.5850 - accuracy: 0.6822 - precision: 0.6805 - auc: 0.7461 - recall: 0.6079 - true_negatives: 1643.0000 - val_loss: 0.6010 - val_accuracy: 0.6609 - val_precision: 0.6726 - val_auc: 0.7311 - val_recall: 0.5710 - val_true_negatives: 534.0000\n",
      "Epoch 17/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.5929 - accuracy: 0.6829 - precision: 0.6756 - auc: 0.7482 - recall: 0.6234 - true_negatives: 1616.0000\n",
      "Epoch 17: val_loss did not improve from 0.60095\n",
      "65/65 [==============================] - 348s 5s/step - loss: 0.5929 - accuracy: 0.6829 - precision: 0.6756 - auc: 0.7482 - recall: 0.6234 - true_negatives: 1616.0000 - val_loss: 0.6185 - val_accuracy: 0.6457 - val_precision: 0.7105 - val_auc: 0.7311 - val_recall: 0.4411 - val_true_negatives: 599.0000\n",
      "Epoch 18/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.5746 - accuracy: 0.6890 - precision: 0.6854 - auc: 0.7573 - recall: 0.6229 - true_negatives: 1642.0000\n",
      "Epoch 18: val_loss improved from 0.60095 to 0.59958, saving model to .\\check.hDf5\n",
      "65/65 [==============================] - 345s 5s/step - loss: 0.5746 - accuracy: 0.6890 - precision: 0.6854 - auc: 0.7573 - recall: 0.6229 - true_negatives: 1642.0000 - val_loss: 0.5996 - val_accuracy: 0.6855 - val_precision: 0.6900 - val_auc: 0.7494 - val_recall: 0.6254 - val_true_negatives: 532.0000\n",
      "Epoch 19/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.5791 - accuracy: 0.6897 - precision: 0.6830 - auc: 0.7614 - recall: 0.6316 - true_negatives: 1628.0000\n",
      "Epoch 19: val_loss did not improve from 0.59958\n",
      "65/65 [==============================] - 336s 5s/step - loss: 0.5791 - accuracy: 0.6897 - precision: 0.6830 - auc: 0.7614 - recall: 0.6316 - true_negatives: 1628.0000 - val_loss: 0.6283 - val_accuracy: 0.6413 - val_precision: 0.7032 - val_auc: 0.7135 - val_recall: 0.4366 - val_true_negatives: 596.0000\n",
      "Epoch 20/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.5804 - accuracy: 0.6858 - precision: 0.7012 - auc: 0.7504 - recall: 0.5755 - true_negatives: 1721.0000\n",
      "Epoch 20: val_loss did not improve from 0.59958\n",
      "65/65 [==============================] - 335s 5s/step - loss: 0.5804 - accuracy: 0.6858 - precision: 0.7012 - auc: 0.7504 - recall: 0.5755 - true_negatives: 1721.0000 - val_loss: 0.6024 - val_accuracy: 0.6746 - val_precision: 0.6778 - val_auc: 0.7445 - val_recall: 0.6133 - val_true_negatives: 525.0000\n",
      "Epoch 21/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.5689 - accuracy: 0.7023 - precision: 0.6919 - auc: 0.7706 - recall: 0.6584 - true_negatives: 1628.0000\n",
      "Epoch 21: val_loss improved from 0.59958 to 0.59197, saving model to .\\check.hDf5\n",
      "65/65 [==============================] - 335s 5s/step - loss: 0.5689 - accuracy: 0.7023 - precision: 0.6919 - auc: 0.7706 - recall: 0.6584 - true_negatives: 1628.0000 - val_loss: 0.5920 - val_accuracy: 0.6935 - val_precision: 0.7242 - val_auc: 0.7500 - val_recall: 0.5831 - val_true_negatives: 571.0000\n",
      "Epoch 22/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.5511 - accuracy: 0.7119 - precision: 0.7117 - auc: 0.7872 - recall: 0.6486 - true_negatives: 1687.0000\n",
      "Epoch 22: val_loss did not improve from 0.59197\n",
      "65/65 [==============================] - 336s 5s/step - loss: 0.5511 - accuracy: 0.7119 - precision: 0.7117 - auc: 0.7872 - recall: 0.6486 - true_negatives: 1687.0000 - val_loss: 0.5950 - val_accuracy: 0.6841 - val_precision: 0.7394 - val_auc: 0.7520 - val_recall: 0.5272 - val_true_negatives: 595.0000\n",
      "Epoch 23/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.5468 - accuracy: 0.7250 - precision: 0.7280 - auc: 0.7948 - recall: 0.6605 - true_negatives: 1718.0000\n",
      "Epoch 23: val_loss did not improve from 0.59197\n",
      "65/65 [==============================] - 335s 5s/step - loss: 0.5468 - accuracy: 0.7250 - precision: 0.7280 - auc: 0.7948 - recall: 0.6605 - true_negatives: 1718.0000 - val_loss: 0.5970 - val_accuracy: 0.6797 - val_precision: 0.7321 - val_auc: 0.7654 - val_recall: 0.5242 - val_true_negatives: 591.0000\n",
      "Epoch 24/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.5486 - accuracy: 0.7158 - precision: 0.7157 - auc: 0.7884 - recall: 0.6538 - true_negatives: 1693.0000\n",
      "Epoch 24: val_loss did not improve from 0.59197\n",
      "65/65 [==============================] - 335s 5s/step - loss: 0.5486 - accuracy: 0.7158 - precision: 0.7157 - auc: 0.7884 - recall: 0.6538 - true_negatives: 1693.0000 - val_loss: 0.6101 - val_accuracy: 0.6717 - val_precision: 0.7470 - val_auc: 0.7416 - val_recall: 0.4773 - val_true_negatives: 611.0000\n",
      "Epoch 25/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.5413 - accuracy: 0.7127 - precision: 0.7156 - auc: 0.7958 - recall: 0.6430 - true_negatives: 1701.0000\n",
      "Epoch 25: val_loss did not improve from 0.59197\n",
      "65/65 [==============================] - 336s 5s/step - loss: 0.5413 - accuracy: 0.7127 - precision: 0.7156 - auc: 0.7958 - recall: 0.6430 - true_negatives: 1701.0000 - val_loss: 0.6041 - val_accuracy: 0.6746 - val_precision: 0.7471 - val_auc: 0.7529 - val_recall: 0.4864 - val_true_negatives: 609.0000\n",
      "Epoch 26/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.5343 - accuracy: 0.7209 - precision: 0.7136 - auc: 0.8003 - recall: 0.6765 - true_negatives: 1670.0000\n",
      "Epoch 26: val_loss improved from 0.59197 to 0.58117, saving model to .\\check.hDf5\n",
      "65/65 [==============================] - 336s 5s/step - loss: 0.5343 - accuracy: 0.7209 - precision: 0.7136 - auc: 0.8003 - recall: 0.6765 - true_negatives: 1670.0000 - val_loss: 0.5812 - val_accuracy: 0.7000 - val_precision: 0.7183 - val_auc: 0.7676 - val_recall: 0.6163 - val_true_negatives: 558.0000\n",
      "Epoch 27/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.5224 - accuracy: 0.7279 - precision: 0.7341 - auc: 0.8122 - recall: 0.6584 - true_negatives: 1734.0000\n",
      "Epoch 27: val_loss did not improve from 0.58117\n",
      "65/65 [==============================] - 336s 5s/step - loss: 0.5224 - accuracy: 0.7279 - precision: 0.7341 - auc: 0.8122 - recall: 0.6584 - true_negatives: 1734.0000 - val_loss: 0.5905 - val_accuracy: 0.7123 - val_precision: 0.6987 - val_auc: 0.7740 - val_recall: 0.7039 - val_true_negatives: 517.0000\n",
      "Epoch 28/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.4965 - accuracy: 0.7463 - precision: 0.7351 - auc: 0.8321 - recall: 0.7177 - true_negatives: 1695.0000\n",
      "Epoch 28: val_loss did not improve from 0.58117\n",
      "65/65 [==============================] - 335s 5s/step - loss: 0.4965 - accuracy: 0.7463 - precision: 0.7351 - auc: 0.8321 - recall: 0.7177 - true_negatives: 1695.0000 - val_loss: 0.5898 - val_accuracy: 0.7087 - val_precision: 0.7305 - val_auc: 0.7621 - val_recall: 0.6224 - val_true_negatives: 566.0000\n",
      "Epoch 29/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.5074 - accuracy: 0.7465 - precision: 0.7486 - auc: 0.8278 - recall: 0.6919 - true_negatives: 1746.0000\n",
      "Epoch 29: val_loss did not improve from 0.58117\n",
      "65/65 [==============================] - 343s 5s/step - loss: 0.5074 - accuracy: 0.7465 - precision: 0.7486 - auc: 0.8278 - recall: 0.6919 - true_negatives: 1746.0000 - val_loss: 0.5845 - val_accuracy: 0.7051 - val_precision: 0.7447 - val_auc: 0.7731 - val_recall: 0.5861 - val_true_negatives: 585.0000\n",
      "Epoch 30/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.5033 - accuracy: 0.7504 - precision: 0.7454 - auc: 0.8332 - recall: 0.7105 - true_negatives: 1726.0000\n",
      "Epoch 30: val_loss did not improve from 0.58117\n",
      "65/65 [==============================] - 338s 5s/step - loss: 0.5033 - accuracy: 0.7504 - precision: 0.7454 - auc: 0.8332 - recall: 0.7105 - true_negatives: 1726.0000 - val_loss: 0.6029 - val_accuracy: 0.6768 - val_precision: 0.7455 - val_auc: 0.7585 - val_recall: 0.4955 - val_true_negatives: 606.0000\n",
      "Epoch 31/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.4793 - accuracy: 0.7608 - precision: 0.7667 - auc: 0.8461 - recall: 0.7043 - true_negatives: 1781.0000\n",
      "Epoch 31: val_loss did not improve from 0.58117\n",
      "65/65 [==============================] - 337s 5s/step - loss: 0.4793 - accuracy: 0.7608 - precision: 0.7667 - auc: 0.8461 - recall: 0.7043 - true_negatives: 1781.0000 - val_loss: 0.5965 - val_accuracy: 0.7145 - val_precision: 0.7068 - val_auc: 0.7757 - val_recall: 0.6918 - val_true_negatives: 528.0000\n",
      "Epoch 32/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.4844 - accuracy: 0.7644 - precision: 0.7710 - auc: 0.8461 - recall: 0.7079 - true_negatives: 1789.0000\n",
      "Epoch 32: val_loss did not improve from 0.58117\n",
      "65/65 [==============================] - 336s 5s/step - loss: 0.4844 - accuracy: 0.7644 - precision: 0.7710 - auc: 0.8461 - recall: 0.7079 - true_negatives: 1789.0000 - val_loss: 0.6072 - val_accuracy: 0.6862 - val_precision: 0.7189 - val_auc: 0.7566 - val_recall: 0.5680 - val_true_negatives: 571.0000\n",
      "Epoch 33/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.4665 - accuracy: 0.7644 - precision: 0.7657 - auc: 0.8547 - recall: 0.7172 - true_negatives: 1771.0000\n",
      "Epoch 33: val_loss did not improve from 0.58117\n",
      "65/65 [==============================] - 336s 5s/step - loss: 0.4665 - accuracy: 0.7644 - precision: 0.7657 - auc: 0.8547 - recall: 0.7172 - true_negatives: 1771.0000 - val_loss: 0.6122 - val_accuracy: 0.6891 - val_precision: 0.7505 - val_auc: 0.7684 - val_recall: 0.5272 - val_true_negatives: 602.0000\n",
      "Epoch 34/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.4613 - accuracy: 0.7728 - precision: 0.7817 - auc: 0.8619 - recall: 0.7156 - true_negatives: 1809.0000\n",
      "Epoch 34: val_loss improved from 0.58117 to 0.57941, saving model to .\\check.hDf5\n",
      "65/65 [==============================] - 335s 5s/step - loss: 0.4613 - accuracy: 0.7728 - precision: 0.7817 - auc: 0.8619 - recall: 0.7156 - true_negatives: 1809.0000 - val_loss: 0.5794 - val_accuracy: 0.7174 - val_precision: 0.7297 - val_auc: 0.7833 - val_recall: 0.6526 - val_true_negatives: 558.0000\n",
      "Epoch 35/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.4646 - accuracy: 0.7695 - precision: 0.7777 - auc: 0.8598 - recall: 0.7120 - true_negatives: 1802.0000\n",
      "Epoch 35: val_loss did not improve from 0.57941\n",
      "65/65 [==============================] - 337s 5s/step - loss: 0.4646 - accuracy: 0.7695 - precision: 0.7777 - auc: 0.8598 - recall: 0.7120 - true_negatives: 1802.0000 - val_loss: 0.6512 - val_accuracy: 0.6558 - val_precision: 0.7679 - val_auc: 0.7549 - val_recall: 0.4048 - val_true_negatives: 637.0000\n",
      "Epoch 36/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.4540 - accuracy: 0.7796 - precision: 0.7915 - auc: 0.8657 - recall: 0.7197 - true_negatives: 1829.0000\n",
      "Epoch 36: val_loss did not improve from 0.57941\n",
      "65/65 [==============================] - 338s 5s/step - loss: 0.4540 - accuracy: 0.7796 - precision: 0.7915 - auc: 0.8657 - recall: 0.7197 - true_negatives: 1829.0000 - val_loss: 0.5892 - val_accuracy: 0.7094 - val_precision: 0.7326 - val_auc: 0.7680 - val_recall: 0.6208 - val_true_negatives: 568.0000\n",
      "Epoch 37/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.4400 - accuracy: 0.7852 - precision: 0.7884 - auc: 0.8739 - recall: 0.7409 - true_negatives: 1811.0000\n",
      "Epoch 37: val_loss did not improve from 0.57941\n",
      "65/65 [==============================] - 337s 5s/step - loss: 0.4400 - accuracy: 0.7852 - precision: 0.7884 - auc: 0.8739 - recall: 0.7409 - true_negatives: 1811.0000 - val_loss: 0.5810 - val_accuracy: 0.7217 - val_precision: 0.7271 - val_auc: 0.7833 - val_recall: 0.6722 - val_true_negatives: 551.0000\n",
      "Epoch 38/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.4318 - accuracy: 0.7934 - precision: 0.7882 - auc: 0.8817 - recall: 0.7651 - true_negatives: 1798.0000\n",
      "Epoch 38: val_loss did not improve from 0.57941\n",
      "65/65 [==============================] - 335s 5s/step - loss: 0.4318 - accuracy: 0.7934 - precision: 0.7882 - auc: 0.8817 - recall: 0.7651 - true_negatives: 1798.0000 - val_loss: 0.6062 - val_accuracy: 0.6913 - val_precision: 0.7521 - val_auc: 0.7561 - val_recall: 0.5317 - val_true_negatives: 602.0000\n",
      "Epoch 39/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.4223 - accuracy: 0.8067 - precision: 0.8089 - auc: 0.8864 - recall: 0.7697 - true_negatives: 1844.0000\n",
      "Epoch 39: val_loss did not improve from 0.57941\n",
      "65/65 [==============================] - 335s 5s/step - loss: 0.4223 - accuracy: 0.8067 - precision: 0.8089 - auc: 0.8864 - recall: 0.7697 - true_negatives: 1844.0000 - val_loss: 0.6056 - val_accuracy: 0.6986 - val_precision: 0.7402 - val_auc: 0.7551 - val_recall: 0.5725 - val_true_negatives: 585.0000\n",
      "Epoch 40/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.4296 - accuracy: 0.7989 - precision: 0.8131 - auc: 0.8823 - recall: 0.7419 - true_negatives: 1866.0000\n",
      "Epoch 40: val_loss did not improve from 0.57941\n",
      "65/65 [==============================] - 335s 5s/step - loss: 0.4296 - accuracy: 0.7989 - precision: 0.8131 - auc: 0.8823 - recall: 0.7419 - true_negatives: 1866.0000 - val_loss: 0.6258 - val_accuracy: 0.6848 - val_precision: 0.7633 - val_auc: 0.7542 - val_recall: 0.4970 - val_true_negatives: 616.0000\n",
      "Epoch 41/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.3983 - accuracy: 0.8108 - precision: 0.8181 - auc: 0.8981 - recall: 0.7671 - true_negatives: 1866.0000\n",
      "Epoch 41: val_loss did not improve from 0.57941\n",
      "65/65 [==============================] - 335s 5s/step - loss: 0.3983 - accuracy: 0.8108 - precision: 0.8181 - auc: 0.8981 - recall: 0.7671 - true_negatives: 1866.0000 - val_loss: 0.6071 - val_accuracy: 0.7167 - val_precision: 0.7459 - val_auc: 0.7707 - val_recall: 0.6208 - val_true_negatives: 578.0000\n",
      "Epoch 42/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.3852 - accuracy: 0.8241 - precision: 0.8383 - auc: 0.9060 - recall: 0.7743 - true_negatives: 1907.0000\n",
      "Epoch 42: val_loss did not improve from 0.57941\n",
      "65/65 [==============================] - 335s 5s/step - loss: 0.3852 - accuracy: 0.8241 - precision: 0.8383 - auc: 0.9060 - recall: 0.7743 - true_negatives: 1907.0000 - val_loss: 0.6084 - val_accuracy: 0.7101 - val_precision: 0.7529 - val_auc: 0.7791 - val_recall: 0.5891 - val_true_negatives: 590.0000\n",
      "Epoch 43/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.3721 - accuracy: 0.8272 - precision: 0.8455 - auc: 0.9136 - recall: 0.7728 - true_negatives: 1923.0000\n",
      "Epoch 43: val_loss did not improve from 0.57941\n",
      "65/65 [==============================] - 337s 5s/step - loss: 0.3721 - accuracy: 0.8272 - precision: 0.8455 - auc: 0.9136 - recall: 0.7728 - true_negatives: 1923.0000 - val_loss: 0.6392 - val_accuracy: 0.7225 - val_precision: 0.7426 - val_auc: 0.7857 - val_recall: 0.6450 - val_true_negatives: 570.0000\n",
      "Epoch 44/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.3945 - accuracy: 0.8296 - precision: 0.8344 - auc: 0.9076 - recall: 0.7944 - true_negatives: 1891.0000\n",
      "Epoch 44: val_loss did not improve from 0.57941\n",
      "65/65 [==============================] - 337s 5s/step - loss: 0.3945 - accuracy: 0.8296 - precision: 0.8344 - auc: 0.9076 - recall: 0.7944 - true_negatives: 1891.0000 - val_loss: 0.5974 - val_accuracy: 0.7116 - val_precision: 0.7463 - val_auc: 0.7710 - val_recall: 0.6042 - val_true_negatives: 582.0000\n",
      "Epoch 45/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.3647 - accuracy: 0.8359 - precision: 0.8506 - auc: 0.9167 - recall: 0.7888 - true_negatives: 1928.0000\n",
      "Epoch 45: val_loss did not improve from 0.57941\n",
      "65/65 [==============================] - 336s 5s/step - loss: 0.3647 - accuracy: 0.8359 - precision: 0.8506 - auc: 0.9167 - recall: 0.7888 - true_negatives: 1928.0000 - val_loss: 0.6411 - val_accuracy: 0.6971 - val_precision: 0.7542 - val_auc: 0.7685 - val_recall: 0.5468 - val_true_negatives: 600.0000\n",
      "Epoch 46/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.3634 - accuracy: 0.8371 - precision: 0.8533 - auc: 0.9182 - recall: 0.7883 - true_negatives: 1934.0000\n",
      "Epoch 46: val_loss did not improve from 0.57941\n",
      "65/65 [==============================] - 336s 5s/step - loss: 0.3634 - accuracy: 0.8371 - precision: 0.8533 - auc: 0.9182 - recall: 0.7883 - true_negatives: 1934.0000 - val_loss: 0.6822 - val_accuracy: 0.7188 - val_precision: 0.7537 - val_auc: 0.7760 - val_recall: 0.6148 - val_true_negatives: 585.0000\n",
      "Epoch 47/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.3522 - accuracy: 0.8478 - precision: 0.8600 - auc: 0.9226 - recall: 0.8068 - true_negatives: 1942.0000\n",
      "Epoch 47: val_loss did not improve from 0.57941\n",
      "65/65 [==============================] - 335s 5s/step - loss: 0.3522 - accuracy: 0.8478 - precision: 0.8600 - auc: 0.9226 - recall: 0.8068 - true_negatives: 1942.0000 - val_loss: 0.6461 - val_accuracy: 0.7254 - val_precision: 0.7235 - val_auc: 0.7860 - val_recall: 0.6918 - val_true_negatives: 543.0000\n",
      "Epoch 48/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.3465 - accuracy: 0.8451 - precision: 0.8656 - auc: 0.9258 - recall: 0.7929 - true_negatives: 1958.0000\n",
      "Epoch 48: val_loss did not improve from 0.57941\n",
      "65/65 [==============================] - 335s 5s/step - loss: 0.3465 - accuracy: 0.8451 - precision: 0.8656 - auc: 0.9258 - recall: 0.7929 - true_negatives: 1958.0000 - val_loss: 0.6671 - val_accuracy: 0.7290 - val_precision: 0.7824 - val_auc: 0.7889 - val_recall: 0.6027 - val_true_negatives: 607.0000\n",
      "Epoch 49/150\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.3406 - accuracy: 0.8579 - precision: 0.8711 - auc: 0.9328 - recall: 0.8181 - true_negatives: 1962.0000\n",
      "Epoch 49: val_loss did not improve from 0.57941\n",
      "65/65 [==============================] - 336s 5s/step - loss: 0.3406 - accuracy: 0.8579 - precision: 0.8711 - auc: 0.9328 - recall: 0.8181 - true_negatives: 1962.0000 - val_loss: 0.6277 - val_accuracy: 0.7188 - val_precision: 0.7175 - val_auc: 0.7880 - val_recall: 0.6828 - val_true_negatives: 540.0000\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "train_X=np.array(train_X)\n",
    "train_y = np.array(train_y)\n",
    "fit_results = model.fit(train_X, train_y,\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(valid_X,valid_y), \n",
    "          callbacks=callbacks_list)\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk!\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model.save('D:\\model\\\\VGG.h5')\n",
    "print('Saved model to disk!')\n",
    "  # serialize weights to HDF5\n",
    "model.save_weights(\"weight.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 19s 436ms/step - loss: 0.5784 - accuracy: 0.7232 - precision: 0.7486 - auc: 0.7930 - recall: 0.6248 - true_negatives: 590.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5784024596214294,\n",
       " 0.7231884002685547,\n",
       " 0.7486238479614258,\n",
       " 0.792981743812561,\n",
       " 0.6248085498809814,\n",
       " 590.0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"./check.hDf5\")\n",
    "model.evaluate(x=test_X, y=test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_test_ds_pointer = h5py.File(os.path.join(feature_dir, 'test_spectrograms.h5'))\n",
    "# for k in full_test_ds_pointer.keys():\n",
    "#     print(k, full_test_ds_pointer[k].shape)\n",
    "# test_files = [x.decode() for x in full_test_ds_pointer['fname'].value]\n",
    "# test_preds = model.predict(full_test_ds_pointer['spectrograms'].value, \n",
    "#                            batch_size=batch_size, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42e085f209e4cb703df1e624cbefcc177b36fe1d52146a22ce249b7f4719e255"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
